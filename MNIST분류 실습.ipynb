{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 1) 1-layer NN\n",
    "## 1) 데이터 확인 및 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MNIST 데이터셋 로드 및 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 로드\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 출력\n",
    "r, c = 10, 10\n",
    "    \n",
    "fig, axs = plt.subplots(r, c)\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(x_train[cnt], cmap='gray')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 500\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 셋 확인\n",
    "print(\"트레이닝 셋의 이미지 데이터모양 : x_train\", x_train.shape)\n",
    "print(\"트레이닝 셋의 부류 데이터모양 : y_train\", y_train.shape)\n",
    "\n",
    "print(\"테스트 셋의 이미지 데이터모양 : x_test\", x_test.shape)\n",
    "print(\"테스트 셋의 부류 데이터모양 : y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리\n",
    "1-hot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-hot code 변경전 첫번째 이미지 부류 데이터 확인\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부류 데이터를 1-hot 코드로 변경\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-hot code 변경후 첫번째 이미지 부류 데이터 확인\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-hot 코드 변경후 모양\n",
    "print(\"1-hot 코드 변경후 모양 : y_train\", y_train.shape)\n",
    "print(\"1-hot 코드 변경후 모양 : y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력데이터 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0~255사이의 값을 -1~1의 값으로 정규화한다.\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 127.5 - 1.\n",
    "x_test = x_test / 127.5 - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28이미지를 784차원 벡터로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 1-Layer 신경망 훈련 (입력노드 784, 출력노드10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/1.PNG \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델 만들기\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter 설정\n",
    "#optimizer, learning late, error function 설정\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#신경망 훈련\n",
    "#배치크기, 훈련기간 설정.\n",
    "#학습데이터 전체를 1번 훈련했을때 1epoch이라고 말함.\n",
    "\n",
    "one_layerNN = model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 그래프 출력\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(one_layerNN.history['val_acc'], 'r', label='val_acc',  fillstyle='none')\n",
    "loss_ax.plot(one_layerNN.history['acc'], 'b', label='train_acc',  fillstyle='none')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('Accuracy (%)')\n",
    "fig.suptitle('Performance of 1-Layer NN')\n",
    "\n",
    "loss_ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얻어진 결과를 아래 사이트와 비교해보세요. <br>\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 2) 2-Layer NN (입력노드 784, 히든노드 30, 출력노드10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/2.PNG \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 만들기\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=784)) #히든노드설정\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter 설정\n",
    "#optimizer, learning late, error function 설정\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#신경망 훈련\n",
    "#배치크기, 훈련기간 설정.\n",
    "#학습데이터 전체를 1번 훈련했을때 1epcoh이라고 말함.\n",
    "\n",
    "two_layerNN = model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 그래프 출력\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(one_layerNN.history['val_acc'], 'r', label='one_layer_val',  fillstyle='none')\n",
    "loss_ax.plot(one_layerNN.history['acc'], 'b', label='one_layer_train',  fillstyle='none')\n",
    "loss_ax.plot(two_layerNN.history['val_acc'], 'k', label='two_layer_val',  fillstyle='none')\n",
    "loss_ax.plot(two_layerNN.history['acc'], 'm', label='two_layer_train',  fillstyle='none')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('Accuracy (%)')\n",
    "fig.suptitle('Comparison result')\n",
    "\n",
    "loss_ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얻어진 결과를 아래 사이트와 비교해보세요. <br>\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yann.lecun.com/exdb/mnist/ <br>\n",
    "hyper parameter와 히든노드수를 조절하여 위사이트의 2-layer NN의 성능과 근접하게 만드세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO:\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=784)) #히든노드설정\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "two_layerNN = model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 3) Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/3.PNG \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 로드\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#데이터 정규화\n",
    "x_train = x_train / 127.5 - 1.\n",
    "x_test = x_test / 127.5 - 1.\n",
    "\n",
    "#1-hot 코드변경\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 (N, H, W, C) 형식으로 변환\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 셋 확인\n",
    "print(\"트레이닝 셋의 이미지 데이터모양 : x_train\", x_train.shape)\n",
    "print(\"트레이닝 셋의 부류 데이터모양 : y_train\", y_train.shape)\n",
    "\n",
    "print(\"테스트 셋의 이미지 데이터모양 : x_test\", x_test.shape)\n",
    "print(\"테스트 셋의 부류 데이터모양 : y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#모델 만들기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(5, kernel_size=3, padding=\"same\", input_shape=(28,28,1)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Conv2D(10, kernel_size=3, padding=\"same\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CNN = model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=64,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yann.lecun.com/exdb/mnist/ <br>\n",
    "hyper parameter와 활성화함수 (activation function) 히든레이어 갯수를 조절하여 위사이트의 CNN 의 성능과 근접하게 만드세요.<br>\n",
    "<br>\n",
    "Tip : relu, maxpooling, categorical_crossentropy, softmax 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
